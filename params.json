{"note":"Don't delete this file! It's used internally to help with page regeneration.","body":"### Introduction\r\n\r\nSmallVCM is a small physically based renderer that implements the vertex\r\nconnection and merging algortihm described in the paper\r\n\r\n> ![a](http://iliyan.com/publications/VertexMerging/teaser_small.png)\r\n> [Light Transport Simulation with Vertex Connection and Merging](http://iliyan.com/publications/VertexMerging)  \r\n>Iliyan Georgiev, Jaroslav Křivánek, Tomáš Davidovič, and Philipp Slusallek  \r\n>_ACM Transactions on Graphics 31(6) (SIGGRAPH Asia 2012)_\r\n\r\nas well as a number of other algorithms, notably including progressive photon\r\nmapping, (progressive) bidirectional photon mapping, and bidirectional path\r\ntracing. The code compiles to a command line program that can render images of a\r\nnumber of predefined scenes using the provided algorithms.\r\n\r\n### Disclaimer\r\n  * Unless really care, you can safely ignore all licenses in the source code.\r\n  * This code is meant for educational purposes, and is not the code that was\r\n    used to render the images in the aforementioned paper. The provided scenes\r\n\tare too simple to provide a complete understanding of the performance of\r\n\tevery implemented rendering algorithm and the differences between them.\r\n  * We are aware that the description below is not as detailed as it can be, and\r\n    appologize for any errors and confusion.\r\n  * If you have any questions and/or input w.r.t. improving and adding\r\n    explanations, feel free to contact Tomáš Davidovič (@tomas-davidovic),\r\n    the primary maintainer of this project, or Iliyan Georgiev (@iliyang),\r\n\tthe primary author of the above paper, and we will figure out whatever you\r\n\tmight need.\r\n\t\r\nWith that out of the way, let's go over the usual stuff.\r\n\r\n### Compilation and Installation\r\n\r\n_Synopsis:_ Compile smallvcm.cxx with OpenMP. If you don't have C++11 support,\r\ndefine `LEGACY_RNG` (automatic for VS2008, found in rng.hxx).\r\n\r\nThe whole program consists of one C++ source file and a multiple header files.\r\nIt was developed in VS2010, however we did some limited testing on Linux, and\r\nthe provided Makefile works for g++ 4.4 and 4.6.3 at least.\r\n\r\nThe major hurdle can come from the fact that the C++11 <random> library is used,\r\nbut an alternative random number generator is also provided (`make old_rng` on\r\nLinux). The code expects OpenMP is available, but getting rid of that is very\r\nstraightforward (simply comment out the few #pragma omp directives in the code).\r\n\r\nOther than that, there are no dependencies, so simply compile smallvcm.cxx.\r\n\r\n### Operation\r\n\r\n_Quick start:_ Run `smallvcm --report -t 10`. In about 5-6 minutes it will\r\ngenerate an index.html file that compares 7 different algorithms on 4 different\r\nCornell box variants (listed below).\r\n\r\nThe features and settings of the program can be explored by running\r\n`smallvcm --help`, which outputs the following information:\r\n\r\n```\r\nUsage: smallvcm [ -s <scene_id> | -a <algorithm> |\r\n           -t <time> | -i <iteration> | -o <output_name> | --report ]\r\n\r\n    -s  Selects the scene (default 0):\r\n          0    glossy small spheres + sun (directional)\r\n          1    glossy large mirror sphere + ceiling (area)\r\n          2    glossy small spheres + point\r\n          3    glossy small spheres + background (env. lighting)\r\n    -a  Selects the rendering algorithm (default vcm):\r\n          el   eye light\r\n          pt   path tracing\r\n          lt   light tracing\r\n          ppm  progressive photon mapping\r\n          bpm  bidirectional photon mapping\r\n          bpt  bidirectional path tracing\r\n          vcm  vertex connection and merging\r\n    -t  Number of seconds to run the algorithm\r\n    -i  Number of iterations to run the algorithm (default 1)\r\n    -o  User specified output name, with extension .bmp or .hdr (default .bmp)\r\n    --report\r\n        Renders all scenes using all algorithms and generates an index.html file\r\n        that displays all images. Obeys the -t and -i options, ignores the rest.\r\n        Recommended usage: --report -i 1   (fastest preview)\r\n        Recommended usage: --report -t 10  (takes 5.5 mins)\r\n        Recommended usage: --report -t 60  (takes 30 mins)\r\n\r\n    Note: Time `-t` takes precedence over iterations `-i` if both are defined\r\n```\r\n\r\n`glossy` applies to the floor of the Cornell box.  \r\n`small spheres` variants have one mirror and one glass spheres in the box.\t\r\n\t\r\nThe program can run in two modes:\r\n\r\n1. If `--report` is not set, a single image of the specified scene will be\r\n   rendered using the specified algorithm. If no option is specified, the output\r\n   is a 512x512 image of scene 0 is rendered using vertex connection and merging\r\n   with 1 iteration.\r\n2. Setting the `--report` option renders all scenes using all algorithms, obeying\r\n   the (optional) number of iterations and/or maximum runtime for each\r\n   scene-algorithm configuration, ignoring the other options.\r\n\r\nAll default settings are set in the `ParseCommandline` function in config.hxx.\r\nSome settings have no command line switch, but can be changed in the code:\r\n<table>\r\n<tr>\r\n  <td>mNumThreads</td><td>Number of rendering threads (default 0, means 1 thread/core)</td>\r\n</tr>\r\n<tr>\r\n  <td>mBaseSeed</td><td>Seed for random number generators (default 1234)</td>\r\n</tr>\r\n<tr>\r\n  <td>mMinPathLength</td><td>Minimal path length (i.e. number of segments) (default 0)</td>\r\n</tr>\r\n<tr>\r\n  <td>mMaxPathLength</td><td>Maximal path length (i.e. number of segments) (default 10)</td>\r\n</tr>\r\n<tr>\r\n  <td>mResolution</td><td>Image resolution (default 512x512)</td>\r\n</tr>\r\n<tr>\r\n  <td>mRadiusFactor</td><td>Scene diameter fraction for the merging radius (default 0.003)</td>\r\n</tr>\r\n<tr>\r\n  <td>mRadiusAlpha</td><td>Merging radius reduction parameter (default 0.75)</td>\r\n</tr>\r\n</table>\r\n\r\n### VertexCM Renderer\r\n\r\nThe `VertexCM` renderer implements a number of algorithms that share almost\r\nidentical code paths. The main differences between the algorithms lie in the\r\nmultiple importance sampling (MIS) weight computation, as well as shortcuts through\r\nunused code. In order to make the understanding of the code easier, below we\r\ndescribe how the `VertexCM` renderer operates. On a high level, it runs in three\r\nstages:\r\n  1. Light sub-path tracing (`ppm`, `bpm`, `bpt`, `vcm`)\r\n  2. Range search hash grid construction over light vertices (`ppm`, `bpm`, `vcm`)\r\n  3. Camera sub-path tracing (all but `lt`)\r\n\r\n`PathVertex` (also `PathElement` variant and typedefs `CameraVertex` and `LightVertex`)\r\nis the basic structure describing the state of a random walk. The only unusual\r\nmembers are `d0`, `d1vc`, `d1vm`, which are used for iterative MIS weight computation:\r\n\r\n<table>\r\n<tr>\r\n  <td>d0</td><td>used for both connections (bpt, vcm) and merging (bpm, vcm)</td>\r\n</tr>\r\n<tr>\r\n  <td>d1vc</td><td>used for connections (bpt, vcm)</td>\r\n</tr>\r\n<tr>\r\n  <td>d1vm</td><td>used for merging (bpm, vcm)</td>\r\n</tr>\r\n</table>\r\n  \r\n_Note:_ All bidirectional algorithms sample the same number of light and camera\r\nsub-paths per iteration, which is the number of pixels in the image. \r\n\r\n* **Light tracing (`lt`)** utilizes only light sub-path tracing. Each path vertex is directly connected\r\n  to camera and then discarded (i.e. not stored). No MIS, hash grid, or camera\r\n  tracing are used.\r\n* **Progressive photon mapping (`ppm`)** traces light sub-paths, storing their\r\n  vertices (as `LightVertex` objects) on\r\n  surfaces with non-specular (i.e. non-delta) materials, and building a hash\r\n  grid over them. The camera sub-paths are traced until hitting a non-specular\r\n  surface, where merging with light vertices (i.e. photon lookup) is performed,\r\n  terminating the camera sub-path thereafter. No MIS is used, and the radiance\r\n  from directly hit lights is accounted for only when all surface interactions\r\n  on the path are specular.\r\n* **Bidirectional photon mapping (`bpm`)** is an extension to `ppm`, which terminates\r\n  camera sub-paths stochastically (unlike `ppm`)\r\n  and performs merging at all non-specular vertices. MIS is used (`d0` and `d1vm`)\r\n  to weight the different possible ways of constructing the same path by merging\r\n  at any (non-specular) interior path vertex.\r\n* **Bidirectional path tracing (`bpt`)**\r\n  Light sub-paths are traced, their non-specular vertices are first connected to\r\n  the camera (as in light tracing) and then stored (without a hash grid). Next,\r\n  the camera sub-paths are traced, connecting each non-specular vertex to a\r\n  light source and to all non-specular vertices of the light sub-path\r\n  corresponding to the current pixel. MIS is used (`d0`, `d1vc`).\r\n* **Vertex connection and merging (`vcm`)**\r\n  is effectively a combination of bidirectional photon mapping and bidirectional\r\n  path tracing. Light sub-path tracing projects and stores the non-specular\r\n  vertices, and also builds a hash grid over them. In the camera sub-path\r\n  tracing, each vertex is connected to a light source, to the vertices of the\r\n  corresponding light sub-path, and also merged with the nearby vertices of all\r\n  light sub-paths. MIS is used (`d0`, `d1vm`, `d1vc`).\r\n\r\n### Features and Limitations\r\n\r\nThe renderer was originally intended to be a compact reference implementation, \r\nakin to SimplePT, however it grew over time. Here is a list of the features and\r\nthe limitations of the framework:\r\n\r\nInfrastructural features:\r\n  * All basic light source types -- area, point, directional, and env. map --\r\n    are supported, although the current env. map implementation uses a constant\r\n\tradiance distribution.\r\n  * Basic surface scattering models are implemented, including diffuse, glossy\r\n    (Phong), as well as specular reflection and refraction. It should be fairly\r\n    straightforward to implement new materials. Also, the material interfaces\r\n    should suffice for most purposes, as the bidirectional algorithms provided\r\n    are already quite demanding on them.\r\n  * The material/shading instance for a given ray hit point is represented by\r\n    a `BSDF` object. In addition to storing the the surface scattering properties,\r\n    this object also holds the local shading frame, as well we the incoming\r\n\t(fixed) direction; all its methods (sample, evaluate, pdf) compute their\r\n\tresults always w.r.t. this direction.\r\n\t\r\nRendering features:\r\n  * A simple renderer with eye light (dot normal) shading for fast previews.\r\n    Red color denotes backface orientation. Implementation is in eyelight.hxx.\r\n  * Traditional path tracing with next even estimation (area and env. map).\r\n    Kept as a separate implementation is in pathtracer.hxx.\r\n  * Light tracing (`lt`), progressive photon mapping (`ppm`), bidirectional photon\r\n    mapping (`bpm`), bidirectional path tracing (`bpt`), and our vertex connection\r\n    and merging (`vcm`). All these are implemented in the `VertexCM` renderer, with\r\n\tcode path switches for the different algorithms.\r\n\r\nLimitations:\r\n  * No acceleration structure for ray intersection (can be added to scene.hxx).\r\n  * Scenes are hard-coded (see `LoadCornellBox` in scene.hxx).\r\n  * The `ppm` algorithm does not handle diffuse+specular materials correctly.\r\n    This limitation can be lifted by adding a parameter to the `BSDF::Sample`\r\n\tmethod that would specify the types of scattering events to be sampled.\r\n\tThe `ppm` implementation could then be modified to continue camera sub-paths\r\n\tonly for the specular parts of diffuse+specular materials.\r\n  * Each area light is an individual triangle, and requires its very own\r\n    material for identification. This can and should be changed if code is\r\n\tused for scenes with complex area light sources. Also, the way of finding\r\n\twhether and which area light is hit by a random ray can be improved.\r\n  * No shading normals. Extending the framework with shading normals should\r\n    happen within the `BSDF` object (which already supports adjoint BSDFs required\r\n\tby refraction).\r\n  * No infrastructural support for participating media or subsurface scattering.\r\n","name":"SmallVCM","tagline":"A (not too) small physically based renderer","google":"UA-35460296-2"}